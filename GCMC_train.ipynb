{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:17.393055Z",
     "start_time": "2019-08-13T12:13:16.543323Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import standard modules\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Import GCMC scripts\n",
    "from GCMC_data_utils import *\n",
    "from GCMC_metrics import *\n",
    "from GCMC_layers import *\n",
    "from GCMC_model import *\n",
    "\n",
    "# Import NN framework\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn\n",
    "from torch.utils import data\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import BatchSampler, SequentialSampler\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:17.396971Z",
     "start_time": "2019-08-13T12:13:17.394486Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_dir = \"D:\\Python\\Thesis\\gcmc_ready_data\\\\\"\n",
    "os.chdir(_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define parameters of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:17.413438Z",
     "start_time": "2019-08-13T12:13:17.398454Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# NN Model dim parameters\n",
    "data_percent = 3 # choose the sampled dataset\n",
    "pickle_in = open(\"gcmc_dims\" + f'{data_percent}' +\".pickle\", \"rb\")\n",
    "dims = pickle.load(pickle_in)\n",
    "\n",
    "num_users = dims['Num_users']\n",
    "num_items = dims['Num_items']\n",
    "num_classes = dims['Num_classes']\n",
    "num_side_features = dims['Num_side_features']\n",
    "\n",
    "# NN hyper-parameters\n",
    "nb = 2\n",
    "emb_dim = 32\n",
    "hidden = [64,32,16,8]\n",
    "dropout = 0.7 # Dropout rate\n",
    "num_epochs = 100\n",
    "val_step = 5\n",
    "test_epoch = 50\n",
    "start_epoch = 0\n",
    "neg_cnt = 100\n",
    "\n",
    "lr = 0.01 # Adam param\n",
    "beta1 = 0.5 # Adam param\n",
    "beta2 = 0.999 # Adam param\n",
    "#decay = 5e-4 # Adam param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:17.431544Z",
     "start_time": "2019-08-13T12:13:17.414927Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Num_users': 1479,\n",
       " 'Num_items': 14427,\n",
       " 'Num_classes': 2,\n",
       " 'Num_features': 15906,\n",
       " 'Num_side_features': 15906}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define directory to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:17.444940Z",
     "start_time": "2019-08-13T12:13:17.433031Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_path = \"D:\\Python\\Thesis\\gcmc_models\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Set up to use GPU // CPU when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:17.690004Z",
     "start_time": "2019-08-13T12:13:17.446920Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import the prepared data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:21.262265Z",
     "start_time": "2019-08-13T12:13:17.691000Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read the necessary files that were created by from GCMC_create_data.ipynb\n",
    "\n",
    "# Read the features\n",
    "\n",
    "u_f = sparse.load_npz(file = 'u_features'+ f'{data_percent}' +'.npz').toarray() # u features\n",
    "v_f = sparse.load_npz(file = 'v_features'+ f'{data_percent}' +'.npz').toarray() # v features\n",
    "u_fs = sparse.load_npz(file = 'u_features_side'+ f'{data_percent}' +'.npz').toarray() # u side feat\n",
    "v_fs = sparse.load_npz(file = 'v_features_side'+ f'{data_percent}' +'.npz').toarray() # v side feat\n",
    "\n",
    "u_features = torch.from_numpy(u_f).float().to(device)\n",
    "v_features = torch.from_numpy(v_f).float().to(device)\n",
    "u_features_side = torch.from_numpy(u_fs).to(device)\n",
    "v_features_side = torch.from_numpy(v_fs).to(device)\n",
    "\n",
    "# Read the train, val and test splits, assumes features and split data are in same directory\n",
    "rating_train = torch.load(f'{data_percent}' +'ratings_tensor_train.pkl').to(device)\n",
    "rating_val = torch.load(f'{data_percent}' +'ratings_tensor_val.pkl').to(device)\n",
    "rating_test = torch.load(f'{data_percent}' +'ratings_tensor_test.pkl').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model definition and show # of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:21.322282Z",
     "start_time": "2019-08-13T12:13:21.265241Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the Graph Auto Encoder model\n",
    "model = GAE(num_users, num_items, num_classes,\n",
    "            num_side_features, nb,\n",
    "            u_features, v_features, u_features_side, v_features_side,\n",
    "            num_users+num_items, emb_dim, hidden, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:21.342121Z",
     "start_time": "2019-08-13T12:13:21.324265Z"
    },
    "code_folding": [
     1,
     5
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAE(\n",
      "  (gcl1): GraphConvolution(\n",
      "    (dropout): Dropout(p=0.7)\n",
      "  )\n",
      "  (gcl2): GraphConvolution(\n",
      "    (dropout): Dropout(p=0.7)\n",
      "  )\n",
      "  (denseu1): Linear(in_features=15906, out_features=32, bias=True)\n",
      "  (densev1): Linear(in_features=15906, out_features=32, bias=True)\n",
      "  (denseu2): Linear(in_features=64, out_features=16, bias=False)\n",
      "  (densev2): Linear(in_features=64, out_features=16, bias=False)\n",
      "  (bilin_dec): BilinearMixture(\n",
      "    (dropout): Dropout(p=0.0)\n",
      "  )\n",
      ")\n",
      "The number of parameters: 3092584\n"
     ]
    }
   ],
   "source": [
    "# Print parameters\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\"\"\"Print out the network information.\"\"\"\n",
    "num_params = 0\n",
    "for p in model.parameters():\n",
    "    num_params += p.numel()\n",
    "print(model)\n",
    "print(\"The number of parameters: {}\".format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:21.346586Z",
     "start_time": "2019-08-13T12:13:21.344106Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_epoch = 0\n",
    "best_loss  = 9999."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Set optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:21.362459Z",
     "start_time": "2019-08-13T12:13:21.349066Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr = lr, \n",
    "                       betas=[beta1, beta2] \n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:21.382815Z",
     "start_time": "2019-08-13T12:13:21.364442Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    \"\"\"Reset the gradient buffers.\"\"\"\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:13:21.399183Z",
     "start_time": "2019-08-13T12:13:21.384303Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train(export):\n",
    "    global best_loss, best_epoch\n",
    "    start = time.perf_counter()\n",
    "    t_loss = []\n",
    "    t_rmse = []\n",
    "    v_loss = []\n",
    "    v_rmse = []\n",
    "    if start_epoch:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_path,\n",
    "                              'model-%d.pkl'%(start_epoch))).state_dict())\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.\n",
    "        train_rmse = 0.\n",
    "        for s, u in enumerate(BatchSampler(SequentialSampler(sample(range(num_users), num_users)),\n",
    "                              batch_size=1024, drop_last=True)): # batch_size = num_users\n",
    "                              #batch_size=args.batch_size, drop_last=False)):\n",
    "            u = torch.from_numpy(np.array(u)).long().to(device)\n",
    "\n",
    "\n",
    "            for t, v in enumerate(BatchSampler(SequentialSampler(sample(range(num_items), num_items)),\n",
    "                                  batch_size=1024, drop_last=True)): # batch_size =num_items\n",
    "                                  #batch_size=args.batch_size, drop_last=False)):\n",
    "                v = torch.from_numpy(np.array(v)).long().to(device)\n",
    "\n",
    "                if len(torch.nonzero(torch.index_select(torch.index_select(rating_train, 1, u), 2, v))) == 0:\n",
    "                    continue\n",
    "\n",
    "                m_hat, loss_ce, loss_rmse = model(u, v, rating_train)\n",
    "\n",
    "                reset_grad()\n",
    "                loss_ce.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss_ce.item()\n",
    "                train_rmse += loss_rmse.item()\n",
    "\n",
    "        log = 'epoch: '+str(epoch+1)+' loss_ce: '  +str(train_loss/(s+1)/(t+1)) \\\n",
    "                                    +' loss_rmse: '+str(train_rmse/(s+1)/(t+1))\n",
    "        print(log)\n",
    "        t_loss.append(train_loss)\n",
    "        t_rmse.append(train_rmse)\n",
    "\n",
    "        if (epoch+1) % val_step == 0:\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                u = torch.from_numpy(np.array(range(num_users))).long().to(device)\n",
    "                v = torch.from_numpy(np.array(range(num_items))).long().to(device)\n",
    "                m_hat, loss_ce, loss_rmse = model(u, v, rating_val)\n",
    "\n",
    "            print('[val loss] : '+str(loss_ce.item())+\n",
    "                  ' [val rmse] : '+str(loss_rmse.item()))\n",
    "            v_loss.append(loss_ce.item())\n",
    "            v_rmse.append(loss_rmse.item())\n",
    "            \n",
    "            if best_loss > loss_rmse.item():\n",
    "                best_loss = loss_rmse.item()\n",
    "                best_epoch= epoch+1\n",
    "                torch.save(model.state_dict(), os.path.join(model_path, 'model-%d.pkl'%(best_epoch)))\n",
    "    \n",
    "    if export == True:\n",
    "        metrics = {\"train_loss\": t_loss,\n",
    "                       \"train_rmse\": t_rmse,\n",
    "                       \"val_loss\": v_loss,\n",
    "                       \"val_rmse\": v_rmse     \n",
    "                  }\n",
    "        out = open(\"D:\\Python\\Thesis\\metrics\\\\gcmc_metrics.pickle\",\"wb\")\n",
    "        pickle.dump(metrics, out)\n",
    "        out.close()        \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    print(\"Time elapsed in mins: \", (time.perf_counter() - start)/60)  \n",
    "    \n",
    "    return t_loss,t_rmse,v_loss,v_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T15:06:11.074488Z",
     "start_time": "2019-08-13T15:06:11.068040Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def test(export):\n",
    "    t_loss = []\n",
    "    t_rmse = []\n",
    "    # Test\n",
    "    model.load_state_dict(torch.load(os.path.join(model_path,\n",
    "                          'model-%d.pkl'%(best_epoch))))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        u = torch.from_numpy(np.array(range(num_users))).long().to(device)\n",
    "        v = torch.from_numpy(np.array(range(num_items))).long().to(device)\n",
    "        m_hat, loss_ce, loss_rmse = model(u, v, rating_test)\n",
    "        \n",
    "    t_loss.append(loss_ce.item())\n",
    "    t_rmse.append(loss_rmse.item())\n",
    "\n",
    "    print('[test loss] : '+str(loss_ce.item()) +\n",
    "          ' [test rmse] : '+str(loss_rmse.item()))\n",
    "    \n",
    "    if export == True:\n",
    "        metrics = {\"test_loss\": t_loss,\n",
    "                       \"test_rmse\": t_rmse,  \n",
    "                  }\n",
    "        out = open(\"D:\\Python\\Thesis\\metrics\\\\gcmc_test_metrics.pickle\",\"wb\")\n",
    "        pickle.dump(metrics, out)\n",
    "        out.close()        \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Execute training and testing procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T12:40:09.294038Z",
     "start_time": "2019-08-13T12:13:21.421485Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss_ce: 0.10563336655364505 loss_rmse: 0.10925683725093092\n",
      "epoch: 2 loss_ce: 0.01927170343697071 loss_rmse: 0.03861894431923117\n",
      "epoch: 3 loss_ce: 0.013858786700958652 loss_rmse: 0.031434098325137584\n",
      "epoch: 4 loss_ce: 0.011711237611182566 loss_rmse: 0.0298767789998757\n",
      "epoch: 5 loss_ce: 0.010927358978993393 loss_rmse: 0.029117566866001914\n",
      "[val loss] : 0.014198663644492626 [val rmse] : 0.02953605353832245\n",
      "epoch: 6 loss_ce: 0.010546791450386601 loss_rmse: 0.029254053752603277\n",
      "epoch: 7 loss_ce: 0.010647448511528117 loss_rmse: 0.029154642884220396\n",
      "epoch: 8 loss_ce: 0.010099851925458227 loss_rmse: 0.028839729194130217\n",
      "epoch: 9 loss_ce: 0.009922067085946245 loss_rmse: 0.027458914056686417\n",
      "epoch: 10 loss_ce: 0.009597428334278188 loss_rmse: 0.02792585182136723\n",
      "[val loss] : 0.014952528290450573 [val rmse] : 0.029218221083283424\n",
      "epoch: 11 loss_ce: 0.009532019383706418 loss_rmse: 0.02751212690158614\n",
      "epoch: 12 loss_ce: 0.009668753765124296 loss_rmse: 0.02799556913253452\n",
      "epoch: 13 loss_ce: 0.009368733787726211 loss_rmse: 0.02717736714319991\n",
      "epoch: 14 loss_ce: 0.009244072095108484 loss_rmse: 0.027075685194826553\n",
      "epoch: 15 loss_ce: 0.0093637802845998 loss_rmse: 0.02709304860660008\n",
      "[val loss] : 0.01463729701936245 [val rmse] : 0.02882237173616886\n",
      "epoch: 16 loss_ce: 0.009006064753131275 loss_rmse: 0.027298161793234094\n",
      "epoch: 17 loss_ce: 0.009024707598395512 loss_rmse: 0.02664628069448684\n",
      "epoch: 18 loss_ce: 0.008761112738284282 loss_rmse: 0.026723695037487363\n",
      "epoch: 19 loss_ce: 0.008724656091154819 loss_rmse: 0.026527101889119616\n",
      "epoch: 20 loss_ce: 0.008917614424717613 loss_rmse: 0.026689208378749236\n",
      "[val loss] : 0.015505568124353886 [val rmse] : 0.028450215235352516\n",
      "epoch: 21 loss_ce: 0.008536125378408801 loss_rmse: 0.026503185209419047\n",
      "epoch: 22 loss_ce: 0.008595535442249716 loss_rmse: 0.026186071569100022\n",
      "epoch: 23 loss_ce: 0.008498210553495613 loss_rmse: 0.02634737199904131\n",
      "epoch: 24 loss_ce: 0.008490381002567509 loss_rmse: 0.026297287799284925\n",
      "epoch: 25 loss_ce: 0.008485824371746276 loss_rmse: 0.026327494964269654\n",
      "[val loss] : 0.015428160317242146 [val rmse] : 0.028370939195156097\n",
      "epoch: 26 loss_ce: 0.008538292261489135 loss_rmse: 0.026568671538760618\n",
      "epoch: 27 loss_ce: 0.008336447019246407 loss_rmse: 0.026244473793277785\n",
      "epoch: 28 loss_ce: 0.008107616493362002 loss_rmse: 0.026237190468236804\n",
      "epoch: 29 loss_ce: 0.008250199580548465 loss_rmse: 0.026010807154567113\n",
      "epoch: 30 loss_ce: 0.008080176884374981 loss_rmse: 0.026050695667176375\n",
      "[val loss] : 0.014904395677149296 [val rmse] : 0.028400830924510956\n",
      "epoch: 31 loss_ce: 0.008154796879223016 loss_rmse: 0.025764638142261122\n",
      "epoch: 32 loss_ce: 0.008091257545207295 loss_rmse: 0.025771293306856284\n",
      "epoch: 33 loss_ce: 0.008059621624332587 loss_rmse: 0.02577670898088919\n",
      "epoch: 34 loss_ce: 0.00809668876172509 loss_rmse: 0.025739382137544453\n",
      "epoch: 35 loss_ce: 0.00781552181641538 loss_rmse: 0.02560182661649638\n",
      "[val loss] : 0.01508165430277586 [val rmse] : 0.028285125270485878\n",
      "epoch: 36 loss_ce: 0.007986082357612239 loss_rmse: 0.025639144986468767\n",
      "epoch: 37 loss_ce: 0.00795987572512656 loss_rmse: 0.02580088676352586\n",
      "epoch: 38 loss_ce: 0.007945246776216663 loss_rmse: 0.025597974184035723\n",
      "epoch: 39 loss_ce: 0.007780999105307274 loss_rmse: 0.02547385638380157\n",
      "epoch: 40 loss_ce: 0.007608796154922207 loss_rmse: 0.02548117719457618\n",
      "[val loss] : 0.014270440675318241 [val rmse] : 0.02818208560347557\n",
      "epoch: 41 loss_ce: 0.007690023480141203 loss_rmse: 0.025281572090794464\n",
      "epoch: 42 loss_ce: 0.0077344739776370785 loss_rmse: 0.025504090074848915\n",
      "epoch: 43 loss_ce: 0.007547568756438393 loss_rmse: 0.025388988832544004\n",
      "epoch: 44 loss_ce: 0.007661337305242861 loss_rmse: 0.025581051312786127\n",
      "epoch: 45 loss_ce: 0.0075789384905614755 loss_rmse: 0.02538049946971504\n",
      "[val loss] : 0.013895390555262566 [val rmse] : 0.028569357469677925\n",
      "epoch: 46 loss_ce: 0.007469911548209244 loss_rmse: 0.02531611907761544\n",
      "epoch: 47 loss_ce: 0.007473275450008389 loss_rmse: 0.025282603497284332\n",
      "epoch: 48 loss_ce: 0.007465983237904895 loss_rmse: 0.02523444510630465\n",
      "epoch: 49 loss_ce: 0.007525945387897082 loss_rmse: 0.025411126486557935\n",
      "epoch: 50 loss_ce: 0.007415482729681701 loss_rmse: 0.02529507303344352\n",
      "[val loss] : 0.013001302257180214 [val rmse] : 0.028382660821080208\n",
      "epoch: 51 loss_ce: 0.007387175164434926 loss_rmse: 0.025327298108355274\n",
      "epoch: 52 loss_ce: 0.007326913809395462 loss_rmse: 0.025185154335174178\n",
      "epoch: 53 loss_ce: 0.007452836917114577 loss_rmse: 0.025445015618710647\n",
      "epoch: 54 loss_ce: 0.007339298035991045 loss_rmse: 0.02505501772144011\n",
      "epoch: 55 loss_ce: 0.007368391024231512 loss_rmse: 0.02511014914073582\n",
      "[val loss] : 0.013102367520332336 [val rmse] : 0.028382964432239532\n",
      "epoch: 56 loss_ce: 0.007161421518373702 loss_rmse: 0.025147792242933065\n",
      "epoch: 57 loss_ce: 0.007157194553656154 loss_rmse: 0.024840802989534234\n",
      "epoch: 58 loss_ce: 0.007242767747292029 loss_rmse: 0.024992431584645862\n",
      "epoch: 59 loss_ce: 0.0071708728844116975 loss_rmse: 0.025121426808514764\n",
      "epoch: 60 loss_ce: 0.007156608512429686 loss_rmse: 0.024942565197956616\n",
      "[val loss] : 0.015695812180638313 [val rmse] : 0.02819073386490345\n",
      "epoch: 61 loss_ce: 0.007061382110415642 loss_rmse: 0.024791388094724556\n",
      "epoch: 62 loss_ce: 0.0070499890041121815 loss_rmse: 0.02472245698611784\n",
      "epoch: 63 loss_ce: 0.007076766511350537 loss_rmse: 0.02475832450519582\n",
      "epoch: 64 loss_ce: 0.007030447319266386 loss_rmse: 0.02475191851512396\n",
      "epoch: 65 loss_ce: 0.007028320063649777 loss_rmse: 0.024714096191538765\n",
      "[val loss] : 0.01697925664484501 [val rmse] : 0.02808348275721073\n",
      "epoch: 66 loss_ce: 0.006878871962856335 loss_rmse: 0.02462610102416615\n",
      "epoch: 67 loss_ce: 0.00693174240976597 loss_rmse: 0.024758489760902842\n",
      "epoch: 68 loss_ce: 0.006918357042325495 loss_rmse: 0.024759806459769607\n",
      "epoch: 69 loss_ce: 0.006787047860728178 loss_rmse: 0.024658182440491925\n",
      "epoch: 70 loss_ce: 0.006880850349781602 loss_rmse: 0.024795404984615743\n",
      "[val loss] : 0.017260434105992317 [val rmse] : 0.02802075818181038\n",
      "epoch: 71 loss_ce: 0.0068710130009484215 loss_rmse: 0.024797117125542303\n",
      "epoch: 72 loss_ce: 0.006847149334134883 loss_rmse: 0.02462943982599037\n",
      "epoch: 73 loss_ce: 0.006774145678459068 loss_rmse: 0.02471233319790502\n",
      "epoch: 74 loss_ce: 0.006835225415021081 loss_rmse: 0.024719492856612697\n",
      "epoch: 75 loss_ce: 0.0067629929820083945 loss_rmse: 0.02470926893875003\n",
      "[val loss] : 0.017027447000145912 [val rmse] : 0.028156407177448273\n",
      "epoch: 76 loss_ce: 0.0066898402931526236 loss_rmse: 0.024665509300705577\n",
      "epoch: 77 loss_ce: 0.006752498339795109 loss_rmse: 0.024846970702388456\n",
      "epoch: 78 loss_ce: 0.006762542482777333 loss_rmse: 0.024801317826911275\n",
      "epoch: 79 loss_ce: 0.00666422108302608 loss_rmse: 0.02470899054398095\n",
      "epoch: 80 loss_ce: 0.006622666699903286 loss_rmse: 0.024723073941588933\n",
      "[val loss] : 0.015380299650132656 [val rmse] : 0.028284618631005287\n",
      "epoch: 81 loss_ce: 0.006682085688745636 loss_rmse: 0.024667933471001952\n",
      "epoch: 82 loss_ce: 0.006593287992083268 loss_rmse: 0.024682514494218464\n",
      "epoch: 83 loss_ce: 0.006575977157418882 loss_rmse: 0.024722974680896317\n",
      "epoch: 84 loss_ce: 0.006553370564818449 loss_rmse: 0.024656299347822954\n",
      "epoch: 85 loss_ce: 0.006634535033039616 loss_rmse: 0.02474791698789756\n",
      "[val loss] : 0.015142694115638733 [val rmse] : 0.02877095341682434\n",
      "epoch: 86 loss_ce: 0.006539552385220304 loss_rmse: 0.02469185388846589\n",
      "epoch: 87 loss_ce: 0.006589441399098307 loss_rmse: 0.024736588637876724\n",
      "epoch: 88 loss_ce: 0.0066202571594788295 loss_rmse: 0.024776037383292402\n",
      "epoch: 89 loss_ce: 0.0065641093200870925 loss_rmse: 0.024723704031202942\n",
      "epoch: 90 loss_ce: 0.006527231080066745 loss_rmse: 0.024739303858950734\n",
      "[val loss] : 0.014427020214498043 [val rmse] : 0.02860519103705883\n",
      "epoch: 91 loss_ce: 0.006627790197463972 loss_rmse: 0.024799220189119557\n",
      "epoch: 92 loss_ce: 0.00652885958801822 loss_rmse: 0.024723758779665723\n",
      "epoch: 93 loss_ce: 0.006635225133712603 loss_rmse: 0.024771025828418454\n",
      "epoch: 94 loss_ce: 0.006570495490450412 loss_rmse: 0.024708223587367684\n",
      "epoch: 95 loss_ce: 0.0065721509662190715 loss_rmse: 0.024774540115946105\n",
      "[val loss] : 0.015586682595312595 [val rmse] : 0.029140204191207886\n",
      "epoch: 96 loss_ce: 0.0065428566480737315 loss_rmse: 0.024699474011348293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 97 loss_ce: 0.006553818108971298 loss_rmse: 0.024703431949352046\n",
      "epoch: 98 loss_ce: 0.006594543991793346 loss_rmse: 0.02477084277364026\n",
      "epoch: 99 loss_ce: 0.006554275485021728 loss_rmse: 0.024722179905178825\n",
      "epoch: 100 loss_ce: 0.006686411016354603 loss_rmse: 0.024761985039471517\n",
      "[val loss] : 0.01471948903053999 [val rmse] : 0.029109638184309006\n",
      "Time elapsed in mins:  26.797555229483333\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_rmse, val_loss, val_rmse = train(export = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T15:06:19.321932Z",
     "start_time": "2019-08-13T15:06:18.088407Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test loss] : 0.0161051657050848 [test rmse] : 0.027401113882660866\n"
     ]
    }
   ],
   "source": [
    "test(export = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
