{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "# Set notation of values \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# To compare both models we need a metric to unify the algorithms. We use RMSE since this approach provides a nice\n",
    "# meaning in the metric. i.e avg difference between what rating we get vs what we predicted\n",
    "\n",
    "def calc_rmse(actual, pred):\n",
    "    \"\"\"\n",
    "    Inputs: actual, a numpy array of our observed data\n",
    "            pred, a numpy array of our predicted data, for NMF it would be W*H\n",
    "    Output: rmse\n",
    "    \"\"\"\n",
    "    I = actual != 0\n",
    "    ME = I * (actual - pred)\n",
    "    MSE = ME**2\n",
    "    \n",
    "    return np.sqrt(((pred - actual) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     7
    ]
   },
   "outputs": [],
   "source": [
    "# prediction function\n",
    "# there are two ways to do prediction: \n",
    "# 1) look at entries of WH on a specific row \n",
    "# 2) np.dot(W[i,:],H[i,:]\n",
    "\n",
    "# point 2 is for comparing other contracts and recommend clauses from them via nearest neighbours\n",
    "\n",
    "def predict(X_hat, actual, ref, filter_actual, idx, n_rec):\n",
    "    \"\"\"\n",
    "    Inputs: X_hat : numpy array, in NMF this is WH, in SVD this is USV\n",
    "            actual: a numpy array, the original X matrix\n",
    "            ref: a pd.DataFrame object, a DataFrame version of X_hat\n",
    "            filter_actual: a boolean value, chooses to get rid of actuals\n",
    "            idx: an integer, contract index\n",
    "            n_rec: an integer, shows top n_rec rows\n",
    "            \n",
    "    Output: pandas DataFrame object, subsetted by idx\n",
    "    \n",
    "    Notes: this function relies on ratings_matrix(), and new_dict3 which is the finalised processed data\n",
    "    new_dict3 = tfidf_summarisation(clauses_list, new_dict2, 10)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Create a df for reference to obtain actual clauses\n",
    "    # Idea is to append this to the table so that we preserve clause \n",
    "    #df_to_get_clauses = ratings_matrix(new_dict3, to_df = True, transpose = False, fill_val = 0)\n",
    "    df_toget_clauses = pd.read_pickle(ref)\n",
    "    clauses = df_to_get_clauses.columns.values\n",
    "    #  Condition to remove actuals and leave preds\n",
    "    if filter_actual == True:\n",
    "        \n",
    "        diff = X_hat - actual\n",
    "        diff = np.clip(diff,0,1)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        diff = X_hat\n",
    "        \n",
    "    print(\"For contract\", idx, \"the top\", n_rec, \"recommended clauses are:\")\n",
    "    \n",
    "    # return the data set subsetted on row by some idx, and sort descending and show n_rec of them\n",
    "    return pd.DataFrame(data=diff[idx,:], index = clauses).sort_values(by=0, axis = 0, ascending = False).head(n_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Ratings Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"ratings_matrix_df.pickle\", \"rb\")\n",
    "X_df = pickle.load(file1)\n",
    "\n",
    "file2 = open(\"ratings_matrix.pickle\", \"rb\")\n",
    "X = pickle.load(file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF\n",
    "\n",
    "Here we employ NMF: Non-negative matrix factorisation.\n",
    "\n",
    "Our goal in NMF is to approximate this matrix by the dot product of two arrays $W$ and $H$. \n",
    "\n",
    "Dimensions of the arrays are defined by dimensions of $X$ and number of components we set to the algorithm. If $X$ has $n$ contracts/rows and $m$ clauses/columns and we want to decompose it to $k$ clauses/columns, then $W$ has $n$ contracts/rows, and $k$ clauses/rows and $H$ has $k$ clauses/rows and $m$ contracts/columns.\n",
    "\n",
    "$X$ is our contract-clauses matrix of dimension $n \\times m$ i.e contracts = rows, clauses = cols\n",
    "\n",
    "$W$ is interpreted as if a contract has clause $y$, what is the additional assignment weight to a group or in our case \"similar-clauses\"\n",
    "\n",
    "$H$ The higher the weight value the more the clause belonging to a group of \"similar-clauses\".\n",
    "\n",
    "Both W,H are initialised as some value - similar to how in NN's weights and biases have an initialisation.\n",
    "\n",
    "Good example and interpretation: https://medium.com/logicai/non-negative-matrix-factorization-for-recommendation-systems-985ca8d5c16c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# Recall that NMF seeks to break down a matrix X into W and H\n",
    "# Such that X ≈ W*H\n",
    "\n",
    "def train_val_NMF_model(data, components, alph, method, verbose):\n",
    "    \"\"\"\n",
    "    Inputs: data: numpy array object, for fit_transform() method\n",
    "            alph: a list object, range of regularisation parameters\n",
    "            components: a list object, range of component parameters\n",
    "            method: a string object, defines what initialisation is needed for NMF training\n",
    "            verbose: boolean value, turns on verbose on or off\n",
    "            \n",
    "    Outputs: errors: a list of frobenius norm of residual matrix between data and the representation(W,H)\n",
    "             config: a list of configurations used to get the errors\n",
    "             Ws: a list of W components for each configuration of [components, alph] s.t X ≈ W*H\n",
    "             Hs: a list of H components for each configuration of [components, alph] s.t X ≈ W*H\n",
    "    \"\"\"\n",
    "    if type(verbose) != bool:\n",
    "        raise ValueError(\"'verbose' variable is not boolean-type, use 'True' or 'False' to control verbose\")\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if type(method) != str:\n",
    "        raise ValueError(\" 'method' variable is not string, see init parameters https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html\")\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    errors = []\n",
    "    config = []\n",
    "    Ws = []\n",
    "    Hs = []\n",
    "    \n",
    "    print(\"Initialisation:\", method)\n",
    "    print(\"Training and validating...\")\n",
    "    for comp in components:\n",
    "        for alphas in alph:\n",
    "\n",
    "            NMF_model = NMF(\n",
    "                        verbose = verbose,\n",
    "                        n_components = comp,\n",
    "                        init = method, \n",
    "                        solver = 'mu',\n",
    "                        beta_loss = 'frobenius', # also called Euclidean Norm\n",
    "                        tol = 1e-4,\n",
    "                        random_state = 0,\n",
    "                        alpha = alphas, # testing out no regularisation\n",
    "                        max_iter = 10000\n",
    "                       )\n",
    "    \n",
    "            W = NMF_model.fit_transform(data)\n",
    "            H = NMF_model.components_\n",
    "\n",
    "            error = NMF_model.reconstruction_err_\n",
    "            \n",
    "            errors.append(error)\n",
    "            config.append([comp, alphas])\n",
    "            Ws.append(W)\n",
    "            Hs.append(H)\n",
    "    \n",
    "    argmin_error = np.argmin(errors)\n",
    "    best_config = config[argmin_error]\n",
    "    best_error = errors[argmin_error]\n",
    "    \n",
    "    print(\"Training and validating complete\")        \n",
    "    print(\"Time elapsed in minutes: \", (time.perf_counter() - start)/60) \n",
    "    print(\"\")\n",
    "    print(\"Best configuration:\", best_config, \"with error:\", best_error)\n",
    "    print(\"Subset W, H at index:\", argmin_error)\n",
    "    print(\"---------------------------------------\")\n",
    "    return errors, config, Ws, Hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_error, r_configs, r_Ws, r_Hs = train_val_NMF_model(X, \n",
    "                                                     [], \n",
    "                                                     [0.01], \n",
    "                                                     'random', \n",
    "                                                     False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMF_Xhat = r_Ws[]@r_Hs[]\n",
    "pd.DataFrame(NMF_Xhat).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(NMF_Xhat, X, True, 14, 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD\n",
    "\n",
    "Core idea of SVD is similar to NMF where we want to express our contract-clauses matrix as a product of matrices in a smaller dimension.\n",
    "\n",
    "The only difference is the training process and the components we obtain. In NMF we obtain two components $W,H$ and in SVD we obtain three components $U,S,V^T$. SVD components are obtained via linear algebra techniques.\n",
    "\n",
    "But there is very little interpretability - hard to explain to non-technical people what is going on.\n",
    "\n",
    "In addition to looking at the entries for predictions, SVD allows approach allows us to project a specific contract into a smaller space and thus compare contracts (via some distance metric) and get recommendations from similar contracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Here we use SVD approach, idea is we want to decompose X = UΣV^(T)\n",
    "\n",
    "def train_val_SVD_model(data, components):\n",
    "    \"\"\"\n",
    "    Inputs: data: numpy array object, for fit_transform() method\n",
    "            components: a list object, range of component parameters\n",
    "            verbose: a boolean value, turns on or off verbose\n",
    "            \n",
    "    Outputs: errors: a list of frobenius norm of residual matrix between data and the representation(W,H)\n",
    "             config: a list of configurations used to get the errors\n",
    "\n",
    "    \"\"\"\n",
    "    start = time.perf_counter()\n",
    "    config = []\n",
    "    U_list = []\n",
    "    S_list = []\n",
    "    V_t_list = []\n",
    "    rmse_list = []\n",
    "    \n",
    "    print(\"Performing tSVD...\")\n",
    "    for comp in components:\n",
    "        print(\"Number of components:\", comp)\n",
    "        \n",
    "        U, S_placeholder, V_t = randomized_svd(\n",
    "                    M = data,\n",
    "                    n_components = comp,\n",
    "                    random_state = 0\n",
    "                    )\n",
    "        # sklearn returns a list of components, but it should be in a matrix where these values are in diagonal entries\n",
    "        S = np.ndarray(shape = (S_placeholder.shape[0],S_placeholder.shape[0]))\n",
    "        np.fill_diagonal(S, S_placeholder)\n",
    "\n",
    "        # Reconstruction of the data\n",
    "        data_pred = U@S@V_t\n",
    "\n",
    "        rmse = calc_rmse(data, data_pred)\n",
    "        \n",
    "        print(\"RMSE:\", rmse)\n",
    "        print(\"\")\n",
    "        \n",
    "        rmse_list.append(rmse)\n",
    "        config.append([comp])\n",
    "        U_list.append(U)\n",
    "        S_list.append(S)\n",
    "        V_t_list.append(V_t)\n",
    "    \n",
    "    lowest_rmse_idx = np.argmin(rmse_list)\n",
    "    \n",
    "    print(\"tSVD complete\") \n",
    "    print(\"Best # of components to choose is\", config[lowest_rmse_idx],\",\",\"Subset on index:\",lowest_rmse_idx)\n",
    "    print(\"Time elapsed in minutes: \", (time.perf_counter() - start)/60) \n",
    "    \n",
    "    return config, U_list, S_list, V_t_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf, U, S, V = train_val_SVD_model(X, \n",
    "                                    [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD_Xhat = U[]@S[]@V[]\n",
    "pd.DataFrame(SVD_Xhat).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(SVD_Xhat, X, True, 21, 10) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
